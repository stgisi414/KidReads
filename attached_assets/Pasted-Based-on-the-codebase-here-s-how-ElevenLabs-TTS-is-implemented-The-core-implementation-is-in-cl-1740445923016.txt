Based on the codebase, here's how ElevenLabs TTS is implemented:

The core implementation is in client/src/hooks/use-elevenlabs.ts. Here are the key components:
Voice ID mapping for different languages
Audio beep functionality for pauses
Error handling and loading states
Fetch call to ElevenLabs API
Audio playback management
Here's a simplified version you can share:

const useElevenLabs = () => {
  const [isLoading, setIsLoading] = useState(false);
  const [error, setError] = useState<string | null>(null);
  const [isPlaying, setIsPlaying] = useState(false);
  const speak = useCallback(async (text: string, options = {}) => {
    if (isPlaying || isLoading) return;
    
    setIsLoading(true);
    setIsPlaying(true);
    setError(null);
    try {
      const response = await fetch(`https://api.elevenlabs.io/v1/text-to-speech/${options.voiceId}`, {
        method: 'POST',
        headers: {
          'Accept': 'audio/mpeg',
          'Content-Type': 'application/json',
          'xi-api-key': 'YOUR_API_KEY',
        },
        body: JSON.stringify({
          text: text,
          model_id: options.modelId || 'eleven_multilingual_v2',
          voice_settings: {
            stability: options.stability || 0.5,
            similarity_boost: options.similarityBoost || 0.75,
          },
        }),
      });
      if (!response.ok) {
        throw new Error(`ElevenLabs API error: ${response.status}`);
      }
      const audioBlob = await response.blob();
      const audioUrl = URL.createObjectURL(audioBlob);
      const audio = new Audio(audioUrl);
      await new Promise((resolve, reject) => {
        audio.onended = resolve;
        audio.onerror = reject;
        audio.play();
      });
      URL.revokeObjectURL(audioUrl);
    } catch (err) {
      setError(err instanceof Error ? err.message : 'Failed to generate speech');
      throw err;
    } finally {
      setIsLoading(false);
      setIsPlaying(false);
    }
  }, [isPlaying, isLoading]);
  return { speak, isLoading, error, isPlaying };
};
Usage example from BeginStudyPage.tsx:
const { speak: elevenLabsSpeak, isLoading: isElevenLabsLoading } = useElevenLabs();
// Using it in a component:
<Button
  onClick={() => elevenLabsSpeak(text, {
    voiceId: "voice_id_here",
    modelId: "eleven_multilingual_v2"
  })}
  disabled={isElevenLabsLoading}
>
  Speak
</Button>
Key points to remember:

Always handle loading and error states
Clean up audio URLs after playback
Use appropriate voice IDs for different languages
Handle the API response as a blob
Create and manage Audio objects properly
Implement proper error handling
This implementation allows for sequential audio playback, handles errors gracefully, and manages loading states appropriately.

Assistant mode
